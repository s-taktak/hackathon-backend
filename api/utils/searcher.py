import torch
import numpy as np
import pickle
from qdrant_client import QdrantClient
from qdrant_client.http import models as qmodels
from pathlib import Path
from transformers import AutoTokenizer, AutoModel
import torch.nn as nn
from api.utils.two_tower_model import TwoTowerModel

# --- è¨­å®š ---
QDRANT_HOST = "qdrant" 
COLLECTION_NAME = "mercari_items"
EMBEDDING_DIM = 128
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_NAME = 'prajjwal1/bert-tiny'

class SafeLabelEncoder:
    def __init__(self):
        self.vocab = {}
        self.unknown_idx = 0 # 0ç•ªã‚’ã€ŒæœªçŸ¥/ãã®ä»–ã€ã«ã™ã‚‹

    def fit(self, values):
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã‚’å–å¾—ã—ã€æ–‡å­—åˆ—ã¨ã—ã¦ã‚½ãƒ¼ãƒˆ
        unique_values = np.unique(values.astype(str))
        # 1ç•ªã‹ã‚‰é€£ç•ªã‚’æŒ¯ã‚‹ (0ç•ªã¯Unknownç”¨ã«ç©ºã‘ã‚‹)
        self.vocab = {val: i + 1 for i, val in enumerate(unique_values)}
        # æ¬¡å…ƒæ•° = ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•° + 1 (Unknownåˆ†)
        self.num_classes = len(self.vocab) + 1

    def transform(self, values):
        # è¾æ›¸ã«ãªã„ã‚‚ã®ã¯ 0 (Unknown) ã«å¤‰æ›ã™ã‚‹
        return np.array([self.vocab.get(str(v), self.unknown_idx) for v in values])
    
try:
    import uvicorn.__main__
    setattr(uvicorn.__main__, 'SafeLabelEncoder', SafeLabelEncoder)
except (ImportError, AttributeError):
    pass # uvicornä»¥å¤–ã§å‹•ã„ã¦ã„ã‚‹ã¨ãã¯ç„¡è¦–

# --- 3. ã‚«ã‚¹ã‚¿ãƒ Unpickler (å¿µã®ãŸã‚ã®ä¿é™º) ---
class CustomUnpickler(pickle.Unpickler):
    def find_class(self, module, name):
        # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°
        # print(f"ğŸ” Unpickling: {module}.{name}") 
        if name == 'SafeLabelEncoder':
            return SafeLabelEncoder
        return super().find_class(module, name)
    

# --- æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚¯ãƒ©ã‚¹ ---
class VectorSearchEngine:
    def __init__(self, model_path: str, encoders_path: str):
        try:
            self.client = QdrantClient(host=QDRANT_HOST, port=6333)
        except:
            self.client = None
            print("âš ï¸ Qdrant connection failed.")

        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
        self.model = None
        self.encoders = None
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        try:
            self._load_resources(model_path, encoders_path)
        except Exception as e:
            print(f"âš ï¸ Model load failed detail: {e}")
            raise e 
        
        if self.client:
            try:
                self._init_collection()
            except Exception as e:
                print(f"âš ï¸ Qdrant init failed: {e}")

    def _load_resources(self, model_path, encoders_path):
        print(f"ğŸ“‚ Loading model from {model_path}...")
        
        with open(encoders_path, 'rb') as f:
            data_pack = CustomUnpickler(f).load()
            self.encoders = data_pack['encoders']
            dims = data_pack['dims']

        self.model = TwoTowerModel(dims).to(DEVICE)
        self.model.load_state_dict(torch.load(model_path, map_location=DEVICE))
        self.model.eval()
        print("âœ… Model loaded successfully.")

    def _init_collection(self):
        try:
            collections = self.client.get_collections()
            exists = any(c.name == COLLECTION_NAME for c in collections.collections)
            if not exists:
                self.client.create_collection(
                    collection_name=COLLECTION_NAME,
                    vectors_config=qmodels.VectorParams(
                        size=EMBEDDING_DIM,
                        distance=qmodels.Distance.COSINE
                    )
                )
                print(f"âœ… Collection '{COLLECTION_NAME}' created.")
        except Exception as e:
            print(f"âš ï¸ Failed to init collection: {e}")

    def encode_single_item(self, item_dict: dict) -> list:
        if not self.model:
            print("âš ï¸ Model is not loaded.")
            return []
        
        self.model.eval()
        with torch.no_grad():
            try:
                # IDã‚’æ–‡å­—åˆ—ã«å¤‰æ› (Noneã¯ '0' ã«)
                def safe_str_id(val):
                    if val is None: return '0'
                    return str(val)

                b_id = safe_str_id(item_dict.get('brand_id'))
                c_id = safe_str_id(item_dict.get('category_id'))
                cond_id = safe_str_id(item_dict.get('condition_id'))

                # SafeLabelEncoderãªã‚‰æœªçŸ¥ã®å€¤ã§ã‚‚ã‚¨ãƒ©ãƒ¼ã«ãªã‚‰ãš 0 ãŒè¿”ã‚‹
                # ãƒªã‚¹ãƒˆå½¢å¼ã§æ¸¡ã—ã¦ [0] ã‚’å–ã‚Šå‡ºã™
                brand_val = self.encoders['brand_id'].transform([b_id])[0]
                cat_val = self.encoders['c2_id'].transform([c_id])[0]
                cond_val = self.encoders['item_condition_id'].transform([cond_id])[0]

                price_val = float(item_dict.get('price', 0))
                price = torch.tensor([np.log1p(price_val)], dtype=torch.float).to(DEVICE)
                brand = torch.tensor([brand_val], dtype=torch.long).to(DEVICE)
                cat = torch.tensor([cat_val], dtype=torch.long).to(DEVICE)
                cond = torch.tensor([cond_val], dtype=torch.long).to(DEVICE)

                inputs = self.tokenizer(
                    item_dict.get('title', ''), 
                    padding='max_length', truncation=True, max_length=32, return_tensors='pt'
                ).to(DEVICE)

                vector = self.model.forward_one_tower(
                    inputs['input_ids'], inputs['attention_mask'],
                    price, brand, cat, cond
                )
                
                print(f"âœ… Vector created for: {item_dict.get('title')[:10]}...")
                return vector.cpu().numpy()[0].tolist()

            except Exception as e:
                import traceback
                print(f"âŒ Vector encoding failed: {e}")
                print(traceback.format_exc())
                return []

    def encode_query(self, query_text: str) -> list:
        if not self.model: return []

        self.model.eval()
        with torch.no_grad():
            try:
                inputs = self.tokenizer(
                    query_text, 
                    padding='max_length', truncation=True, max_length=32, return_tensors='pt'
                ).to(DEVICE)

                dummy_price = torch.tensor([np.log1p(3000.0)], dtype=torch.float).to(DEVICE)
                dummy_id = torch.tensor([0], dtype=torch.long).to(DEVICE)

                vector = self.model.forward_one_tower(
                    inputs['input_ids'], 
                    inputs['attention_mask'],
                    dummy_price, dummy_id, dummy_id, dummy_id
                )
                
                return vector.cpu().numpy()[0].tolist()

            except Exception as e:
                print(f"âŒ Query encoding failed: {e}")
                return []
        
    def encode_query(self, query_text: str) -> list[float]:
        """
        æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã—ã¦è¿”ã™
        ï¼ˆã‚«ãƒ†ã‚´ãƒªã‚„ä¾¡æ ¼ã¯ä¸æ˜ãªã®ã§ã€ãƒ€ãƒŸãƒ¼å€¤ã‚’å…¥ã‚Œã¦æ¨è«–ã™ã‚‹ï¼‰
        """
        self.model.eval()
        with torch.no_grad():
            try:
                # ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º
                inputs = self.tokenizer(
                    query_text, 
                    padding='max_length', truncation=True, max_length=32, return_tensors='pt'
                ).to(DEVICE)

                # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
                # æ¤œç´¢ã‚¯ã‚¨ãƒªã«ã¯ã€Œä¾¡æ ¼ã€ã‚„ã€Œãƒ–ãƒ©ãƒ³ãƒ‰ã€ã®æ¦‚å¿µãŒãªã„ãŸã‚ã€
                # ãƒ¢ãƒ‡ãƒ«ãŒæ··ä¹±ã—ãªã„ã‚ˆã†ã€Œ0 (Unknown)ã€ã‚„ã€Œå¹³å‡çš„ãªå€¤ã€ã‚’å…¥ã‚Œã¾ã™
                dummy_price = torch.tensor([np.log1p(3000.0)], dtype=torch.float).to(DEVICE) # ä»®ã®ä¾¡æ ¼
                dummy_id = torch.tensor([0], dtype=torch.long).to(DEVICE) # Unknown ID

                # æ¨è«– (forward_one_tower)
                vector = self.model.forward_one_tower(
                    inputs['input_ids'], 
                    inputs['attention_mask'],
                    dummy_price, # price
                    dummy_id,    # brand
                    dummy_id,    # category
                    dummy_id     # condition
                )
                
                # Pythonã®ãƒªã‚¹ãƒˆã«å¤‰æ›ã—ã¦è¿”ã™ ([0.123, ...])
                return vector.cpu().numpy()[0].tolist()

            except Exception as e:
                print(f"âŒ Query encoding failed: {e}")
                return []
        
    def create_index(self, items: list[dict]):
        """
        å…¨å•†å“ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ä¿å­˜ã™ã‚‹
        items: [{"id": "uuid", "title": "name", "price": 1000, ...}, ...] ã®ãƒªã‚¹ãƒˆ
        """
        print(f"ğŸ”„ {len(items)}ä»¶ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆä¸­...")
        vectors = []
        ids = []
        
        with torch.no_grad():
            for item in items:
                try:
                    # IDå¤‰æ› (æœªçŸ¥ã®å€¤ã¯0ç•ª=Unknownã«å¤‰æ›)
                    # DBã‹ã‚‰æ¥ã‚‹å€¤ã¯æ–‡å­—åˆ—ã‚„IntãŒæ··ã–ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ str() ã§çµ±ä¸€
                    b_id = str(item.get('brand_id', '0'))
                    c_id = str(item.get('category_id', '0')) # DBã®ã‚«ãƒ©ãƒ åã«åˆã‚ã›ã¦èª¿æ•´
                    cond_id = str(item.get('condition_id', '0'))

                    brand_val = self.encoders['brand_id'].transform([b_id])[0]
                    cat_val = self.encoders['c2_id'].transform([c_id])[0] # å­¦ç¿’æ™‚ã®ã‚­ãƒ¼å 'c2_id' ã«åˆã‚ã›ã‚‹
                    cond_val = self.encoders['item_condition_id'].transform([cond_id])[0]

                    # TensoråŒ–
                    price = torch.tensor([np.log1p(float(item.get('price', 0)))], dtype=torch.float).to(DEVICE)
                    brand = torch.tensor([brand_val], dtype=torch.long).to(DEVICE)
                    cat = torch.tensor([cat_val], dtype=torch.long).to(DEVICE)
                    cond = torch.tensor([cond_val], dtype=torch.long).to(DEVICE)

                    # ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
                    inputs = self.tokenizer(
                        item.get('title', ''), 
                        padding='max_length', truncation=True, max_length=32, return_tensors='pt'
                    ).to(DEVICE)

                    # ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
                    vec = self.model.forward_one_tower(
                        inputs['input_ids'], inputs['attention_mask'],
                        price, brand, cat, cond
                    )
                    vectors.append(vec.cpu())
                    ids.append(str(item['id']))
                    
                except Exception as e:
                    print(f"Skipping item {item.get('id')}: {e}")
                    continue

        if not vectors:
            print("âš ï¸ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã§ãã‚‹ã‚¢ã‚¤ãƒ†ãƒ ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return

        # çµåˆã—ã¦ä¿å­˜
        self.index_vectors = torch.cat(vectors)
        self.index_ids = ids
        
        with open(self.index_path, 'wb') as f:
            pickle.dump({'vectors': self.index_vectors, 'ids': self.index_ids}, f)
        print("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†")

    def load_index(self):
        """ä¿å­˜ã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã‚€"""
        if not self.index_path.exists():
            return
        
        with open(self.index_path, 'rb') as f:
            data = pickle.load(f)
            self.index_vectors = data['vectors'].to(DEVICE)
            self.index_ids = data['ids']
        print(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­è¾¼å®Œäº†: {len(self.index_ids)}ä»¶")

    def search(self, query: str, top_k: int = 10):
        """æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹"""
        if self.index_vectors is None:
            return []

        # ã‚¯ã‚¨ãƒªã®ãƒ™ã‚¯ãƒˆãƒ«åŒ– (ä¾¡æ ¼ãªã©ã¯ãƒ€ãƒŸãƒ¼å€¤ã‚’å…¥ã‚Œã‚‹)
        with torch.no_grad():
            inputs = self.tokenizer(
                query, padding='max_length', truncation=True, max_length=32, return_tensors='pt'
            ).to(DEVICE)
            
            # æ¤œç´¢ã‚¯ã‚¨ãƒªã«ã¯ã€Œæ¡ä»¶ã€ãŒãªã„ã®ã§å…¨ã¦0(Unknown)ã‚„å¹³å‡å€¤ã‚’å…¥ã‚Œã‚‹
            dummy_price = torch.tensor([np.log1p(3000.0)], dtype=torch.float).to(DEVICE) # ä»®ã®å¹³å‡ä¾¡æ ¼
            dummy_id = torch.tensor([0], dtype=torch.long).to(DEVICE)

            query_vec = self.model.forward_one_tower(
                inputs['input_ids'], inputs['attention_mask'],
                dummy_price, dummy_id, dummy_id, dummy_id
            )

        # é¡ä¼¼åº¦è¨ˆç®— (ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦)
        scores = torch.matmul(query_vec, self.index_vectors.T).squeeze(0)
        
        # ä¸Šä½å–å¾—
        k = min(top_k, len(self.index_ids))
        top_scores, top_indices = torch.topk(scores, k=k)
        
        # IDãƒªã‚¹ãƒˆã‚’è¿”ã™
        results = [self.index_ids[i] for i in top_indices.cpu().numpy()]
        return results